{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78-2-HFZmy1C"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import stats\n",
    "plt.rc('font', size=16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian(ax, mean, cov, color='red', size=3):\n",
    "    # draws ellipses representing different standard deviations (size is the number of ellipses)\n",
    "    # width and height are times by 2 since sqrt of the eigenval only measures half the distance\n",
    "    eig_w, eig_v = np.linalg.eig(cov)    \n",
    "    for i in range(size):\n",
    "        ell = Ellipse(xy=[mean[0], mean[1]], \n",
    "                      width=np.sqrt(eig_w[0]) * 2 * (i + 1), \n",
    "                      height=np.sqrt(eig_w[1]) * 2 * (i + 1), \n",
    "                      angle=np.rad2deg(np.arccos(eig_v[0, 0])), \n",
    "                      edgecolor=color, lw=2, facecolor='none')\n",
    "        ax.add_artist(ell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0hzVF3knGGa"
   },
   "source": [
    "# $\\star$ Question 1:\n",
    "\n",
    "Run the Sklearn implementations of k-means and expectation maximization on the dataset *gaussianplus.npz*.\n",
    "\n",
    "\n",
    "Plot the estimated assignments and the estimated\n",
    "parameters of the two Gaussians. \n",
    "\n",
    "Describe how the fitting by expectation maximization outperforms the one with k-means.\n",
    "\n",
    "Try with varying, also\n",
    "very bad initializations. How stable are the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzPFK-xXnJi0"
   },
   "outputs": [],
   "source": [
    "# Load and visualize the dataset (as in previous exercises):\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_k_means(data, init='random', k=2): \n",
    "    \"\"\"\n",
    "    Runs the K-means algorithm from sklearn on the input data and plots the results. \n",
    "    \n",
    "    Args:\n",
    "        data: Input data.\n",
    "        init: Initialization method (see the sklearn documentation).\n",
    "        k : Number of clusters.\n",
    "    \"\"\"\n",
    "    # Apply the K-Means clustering implementation from sklearn (see documentation for usage instructions).\n",
    "    # Store the cluster assignments in a variable called 'labels' and the cluster centroids in a \n",
    "    # variable called 'centroids':\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Print centroids:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Plot results (plot datapoints and centroids; color points according to the cluster assignment):\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "# run with random init:\n",
    "run_and_plot_k_means(data, init='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with manual init:\n",
    "run_and_plot_k_means(data, init=np.array([[16,16], [14,14]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run EM algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_em(data, means_init=None, k=2): \n",
    "    \"\"\"\n",
    "    Runs the EM algorithm from sklearn on the input data and plots the results. \n",
    "    \n",
    "    Args:\n",
    "        data: Input data.\n",
    "        means_init: Initial means of the gaussians.\n",
    "        k: Number of mixture components.\n",
    "    \"\"\"\n",
    "    # Apply the EM-algorithm implementation from sklearn (see documentation for usage instructions).\n",
    "    # Store the cluster assignments in a variable called 'labels', the estimated means in a variable 'means',\n",
    "    # the estimated weights in a variable 'weights' and the estimated covariances in a variable 'covariances':\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Print means and mixture weights:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Plot results:\n",
    "    # (plot datapoints and centroids; color points according to the cluster assignment; \n",
    "    # plot covariances with the plot_gaussian function)\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "# run with random init:\n",
    "run_and_plot_em(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with manual init:\n",
    "run_and_plot_em(data, means_init=np.array([[16,16], [10,10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6kyRTFRnJ6j"
   },
   "source": [
    "# $\\star\\star\\star$  Question 2:\n",
    "\n",
    "Build your own implementations of k-means and EM to learn in\n",
    "detail how these important algorithms work.\n",
    "\n",
    "Compare your implementation with the sklearn\n",
    "implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_ySDrzknOpV"
   },
   "source": [
    "## Custom K-means implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleKMeans:\n",
    "    def __init__(self, k, mean_init, num_iters=100):\n",
    "        \"\"\"Custom k-means implementation.\n",
    "        \n",
    "        Args:\n",
    "            k: Number of clusters.\n",
    "            mean_init: Initial cluster means as np array of shape (num_clusters, dimensions).\n",
    "            num_iters: Number of iterations.\n",
    "        \"\"\"\n",
    "        self.centroids = mean_init.astype(np.float)\n",
    "        self.labels = None\n",
    "        self.num_iters = num_iters\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, data):\n",
    "        # run k-means on the data and store results in self.centroids and self.labels:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_simple_k_means(data, init=np.array([[4,4], [10,4]]), k=2, num_iters=10): \n",
    "    \"\"\"Runs the custom K-means implementation on the input data and plots the results. \n",
    "    \n",
    "    Args:\n",
    "        data: Input data.\n",
    "        init: Initial cluster centroids.\n",
    "        k : Number of clusters.\n",
    "        num_iters : Number of iterations.\n",
    "    \"\"\"\n",
    "    # Apply the custom K-Means clustering implementation.\n",
    "    # Store the cluster assignments in a variable called 'labels' and the cluster centroids in a \n",
    "    # variable called 'centroids':\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Print centroids:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Plot results (plot datapoints and centroids; color points according to the cluster assignment):\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "# Run our implementation of simple k-means:\n",
    "run_and_plot_simple_k_means(data, init=np.array([[6,6], [4,5] ]), k=2, num_iters=10)\n",
    "\n",
    "\n",
    "# Compare to the sklearn implementation of k-means:\n",
    "run_and_plot_k_means(data, init=np.array([[6,6], [4,5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom EM algorithm implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEM:\n",
    "    def __init__(self, means_init=None, k=2, num_iters=10):\n",
    "        # initialize attributes:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def fit(self, data): \n",
    "        # run the em algorithm on the data and store results self.means, self.sigmas, self.pi, self.labels:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot_simple_em(data, means_init=None, k=2, num_iters=10): \n",
    "    \"\"\"\n",
    "    Runs the custom EM algorithm implementation on the input data and plots the results. \n",
    "    \n",
    "    Args:\n",
    "        data: Input data.\n",
    "        means_init: Initial means of the gaussians.\n",
    "        k: Number of mixture components.\n",
    "        num_iters: Number of iterations.\n",
    "    \"\"\"\n",
    "    # Apply the custom EM-algorithm implementation.\n",
    "    # Store the cluster assignments in a variable called 'labels', the estimated means in a variable 'means',\n",
    "    # the estimated weights in a variable 'weights' and the estimated covariances in a variable 'covariances':\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Print means and mixture weights:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Plot results:\n",
    "    # (plot datapoints and centroids; color points according to the cluster assignment; \n",
    "    # plot covariances with the plot_gaussian function)\n",
    "    raise NotImplementedError\n",
    "    \n",
    "# Run our implementation of the EM algorithm:\n",
    "run_and_plot_simple_em(data, k=2, num_iters=50)\n",
    "\n",
    "\n",
    "# Compare to the sklearn implementation of the EM algorithm:\n",
    "run_and_plot_em(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch-1.9-20.04",
   "language": "python",
   "name": "torch-1.9-20.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
