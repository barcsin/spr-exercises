{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise7SPR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1han4RcYoGZK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlOdQz9d2zhs"
      },
      "source": [
        "# $\\star$ Question 1:\n",
        "Load the data from dataset.npz (you know this dataset already from class 4) and split it evenly into a training set and a test set. \n",
        "\n",
        "Train a generative classifier using Gaussian distributions on the training set. (Hint: This comes down to estimating the parameters of a Gaussian distribution\n",
        "for each class.) \n",
        "\n",
        "Then compute the average classification error on the test\n",
        "set. Compare it to the error you got with the nearest neighbor classifier.\n",
        "\n",
        "\n",
        "\n",
        "Visualize the training points and the classified points and mark\n",
        "misclassifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiSKAhvM2zo7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leR2Hbxp2zw7"
      },
      "source": [
        "# $\\star$ $\\star$  Question 2:\n",
        "\n",
        "Train a discriminative classifier via logistic regression and $\\phi(x) = x$\n",
        "\n",
        "For optimization use gradient descent.\n",
        "\n",
        "This corresponds to training a\n",
        "single layer neural network. \n",
        "\n",
        "The cost function is convex, so you will find\n",
        "the global optimum no matter how you initialize the weights. If your energy\n",
        "oscillates, you must reduce the step size (learning rate). \n",
        "\n",
        "Compute the average classification error and visualize the result. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hxsS7F12z67"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}